---
title: "Rolling Sales Data Analysis - Manhattan"
author: "Shrey Patel"
date: "12/15/2021"
output:
  pdf_document:
    latex_engine : pdflatex
    number_sections: True
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tibble)
library(ggplot2)
library(tidyverse)
library(ggforce)
library(dplyr)
```

```{r, include=FALSE}
# excel file converted to csv and read
sales <- read.csv("rollingsales_manhattan.csv", skip=5, header=FALSE)
colnames(sales) <- c("borough", "neighborhood", "building_class_category", "tax_class_at_present", "block", "lot", "easement", 
                    "building_class_at_present", "address", "apartment_number", "zipcode", "residential_units", "commercial_units", 
                    "total_units", "land_sqft", "gross_sqft", "year_built", "tax_class_at_sale", "building_class_at_sale",
                    "sale_price","sale_date")

#View(sales)

sales_data <- as_tibble(sales)

# removing borough, easement, address, and apartment number columns
sales_data <- sales_data %>% select(-c(borough,easement,address,apartment_number,gross_sqft))

# converting land sq.feet, gross sq.feet, and sale price to numeric 
sales_data$land_sqft = as.numeric(gsub(",", "", sales_data$land_sqft))
sales_data$sale_price = as.numeric(gsub(",", "", sales_data$sale_price))

summary(sales_data)

# converting the character type variables and some numeric type variables to factors
sales_data$neighborhood <- factor(sales_data$neighborhood)
sales_data$building_class_category <- factor(sales_data$building_class_category)
sales_data$tax_class_at_present <- factor(sales_data$tax_class_at_present)
#sales_data$block <- factor(sales_data$block)
#sales_data$lot <- factor(sales_data$lot)
sales_data$building_class_at_present <- factor(sales_data$building_class_at_present)
sales_data$zipcode <- factor(sales_data$zipcode)
sales_data$residential_units <- factor(sales_data$residential_units)
sales_data$commercial_units <- factor(sales_data$commercial_units)
sales_data$total_units <- factor(sales_data$total_units)
sales_data$year_built <- factor(sales_data$year_built)
sales_data$tax_class_at_sale <- factor(sales_data$tax_class_at_sale)
sales_data$building_class_at_sale <- factor(sales_data$building_class_at_sale)

# converting the date column to date type
sales_data$sale_date <- as.Date(sales_data$sale_date, "%m/%d/%Y")
```

# Abstract

In this study, I have predicted the land square feet area for properties using a multinomial Logistic Regression classifier while considering features like: the neighborhood, the building class category, block, lot, tax class at sale, building class at sale, and sale price. This study was done to semi-impute (assign a range instead of an exact value) the missing data with respect to the land square feet variable. Post-analyses, I can conclude that the multinomial logistic regression classifier is better at predicting the land square feet area for large buildings and for those that fall under tax class #4.

# Introduction

Variables like land square feet area, gross square feet area, number of residential and commercial units, play a huge role in deciding whether a property is worth buying at a given price. Considering the amount of missing data in the sales data set, it is essential to impute or at least semi-impute the missing land square feet area information. In this study, I have performed exploratory data analysis to answer the following questions:

- What is the distribution of sale prices for each tax class?
- What is the distribution of number of sales over time for each tax class? Identify months where the sales peaked or dipped.
- What is the trend with respect to the sale price and the number of sale over time for each tax class?

Finally, I performed predictive analysis to predict a range of land square feet values that a property might fall under. 

# Data

The data set used in this study is publicly available on the [NYC department of finance](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page). The data contains rolling sales data for a time range between December 2020 and November 2021. There are a total of 20,853 observations and 21 features. For predictive analysis, I created a new target variable, Area from the land square feet variable. The target variable takes four values based on the conditions below:

```{r, echo=FALSE, out.width="200%", out.width= "25%", out.width= "25%", out.extra='style="float:right"'}
knitr::include_graphics("target_var_area.jpg")
```

The four values represent the inter-quantile ranges. Hence, the labels are well-balanced.

# Analyses

## Pre-processing the Data

Following columns were removed:

- Borough: This variable contains the same value for all observations
- Easement: This is an empty column
- Address & Apartment Number: These variables will not be needed for the analyses.
- Gross square feet: With 97% of the gross square feet information missing, it is quite difficult to impute.

Land square feet and sale price variables were converted to numeric. The rest of the variables were converted to factors. The sales date column was converted to a date type column.

Following measures were taken to handle missing data:

- All observations with sale price $1000 or lower were removed.
- All observations with missing land square feet area and year built were removed.
- Duplicate rows were removed, if any.

The resulting data set consists of 947 observation.

## Exploratory Analyses

- What is the distribution of sale prices for each tax class?
```{r, include=FALSE}
ggplot(data=sales_data, mapping=aes(x=sale_price, color=tax_class_at_sale)) +
  geom_density() +
  facet_zoom(xlim = c(0, 10000000))
  ggtitle("Distribution of sale prices less than $10M")
```

- What is the distribution of number of sales over time for each tax class? Identify months where the sales peaked or dipped.
```{r, include=FALSE}
sales_data %>% 
  filter(tax_class_at_sale == 1) %>%
  ggplot(aes(x = sale_date)) + 
  geom_freqpoly(binwidth = 12) +
  ggtitle("Frequency polygon of sale dates - tax class 1")

sales_data %>% 
  filter(tax_class_at_sale == 2) %>%
  ggplot(aes(x = sale_date)) + 
  geom_freqpoly(binwidth = 12) +
  ggtitle("Frequency polygon of sale dates - tax class 2")

sales_data %>% 
  filter(tax_class_at_sale == 4) %>%
  ggplot(aes(x = sale_date)) + 
  geom_freqpoly(binwidth = 12) +
  ggtitle("Frequency polygon of sale dates - tax class 4")
```  

- What is the trend with respect to the sale price and the number of sale over time for each tax class?
```{r, include=FALSE}
ggplot(data = sales_data) +
  geom_point(mapping = aes(x = sale_date, y = sale_price, color = tax_class_at_sale), alpha = 0.75) +
  coord_cartesian(ylim = c(0, 100000000))+
  ggtitle("Sale prices over the months")
```


## Predictive Analysis

A multinomial logistic regression classifier was trained and tested using a 70/30:train/test split with 'Area' as the target variable and neighborhood, building class category, block, lot, tax class at sale, and building class at sale as the independent variables. The residual deviance and the AIC of the classifier were 815.033 and 1457.033, respectively. The classifier using maximum likelihood estimation to assign four probabilities (one for each target label) to each observation. The class with the highest probability gets chosen as the predicted class. 

```{r, include=FALSE}
# Removing sales less than $1000
sales_data <- filter(sales_data, sale_price>1000)

# Removing missing data
sales_data <- filter(sales_data, !is.na(sales_data$year_built), !is.na(sales_data$land_sqft))
dim(sales_data)

# Remove duplicate rows if any
sales_data <- sales_data %>% distinct()

summary(sales_data)
sapply(sales_data, function(x) sum(is.na(x)))
dim(sales_data)


#### Analysis ####
library(caret)
require(nnet)

# creating a target variable, Area, from land square feet column
sales_data <- sales_data %>%
  mutate(Area = case_when(land_sqft<=1754 ~ 1,
                          land_sqft<=2300 ~ 2,
                          land_sqft<=4112 ~ 3,
                          land_sqft<=659375 ~ 4))

sales_data <- sales_data %>% select(-c(land_sqft))
sales_data$Area <- factor(sales_data$Area)


summary(sales_data)

# splitting the data set
sales_data <- select(sales_data, c("neighborhood", "building_class_category", "block", "lot", "tax_class_at_sale", "building_class_at_sale",
                                   "sale_price", "Area"))

features = setdiff(names(sales_data),'Area')
summary(sales_data)

index <- createDataPartition(sales_data$Area, p = .70, list = FALSE)
train <- sales_data[index,]
test <- sales_data[-index,]

# Setting the reference level since this is a multinomial classifier
train$Area <- relevel(train$Area, ref = 1)

# Training the multinomial model
multinom_model <- multinom(train$Area ~ ., data = train[1:7])

# Checking the model
summary(multinom_model)

# converting coefficients to odds
exp(coef(multinom_model))

# Predicting the class for test dataset
test$ClassPredicted <- predict(multinom_model, newdata = test[1:7], "class")
```


```{r, include=FALSE}
head(round(fitted(multinom_model), 2))
confusionMatrix(table(test$ClassPredicted, 
                      test$Area), positive="1")
```

# Conclusion

From the above analyses can draw the following conclusions:
